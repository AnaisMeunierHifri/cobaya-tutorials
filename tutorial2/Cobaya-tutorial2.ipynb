{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General python imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import os, sys \n",
    "\n",
    "# Import corresponding modules from GetDist\n",
    "from getdist.mcsamples import loadMCSamples, MCSamplesFromCobaya\n",
    "import getdist.plots as gdplt\n",
    "\n",
    "\n",
    "# Matplotlib params set-up for nice plots\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "plt.rc('font',size=25)\n",
    "plt.rc('axes', titlesize=26)\n",
    "plt.rc('axes', labelsize=25)\n",
    "plt.rc('lines', linewidth=2)\n",
    "plt.rc('lines', markersize=6)\n",
    "plt.rc('legend', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced tutorial 2\n",
    "\n",
    "\n",
    "**Description**: this jupyter notebook is designed to help you solve the exercises planned for this advanced practical session. For this, we will use the CMB measurements of `Planck18` to deal as the observational probes to constrain the Standard Cosmological Model. We will use `Cobaya` as the main Bayesian Analysis tool and `CAMB` as the Boltzmann Solver.\n",
    "\n",
    "\n",
    "### Exercises: \n",
    "\n",
    "* **Exercise 0**: Plot the chains from the previous tutorial to see the evolution\n",
    "\n",
    "* **Exercise 1**: Make an evaluation of the posterior distribution by running Cobaya with its model wrapper and the full Planck18 data set (temperature and polarization). Repeat for the full Planck18 data including lensing. Think about the values of the likelihood and the posterior. Why are they varying? What are we sampling?\n",
    "\n",
    "* **Exercise 2**: Plot the CMB Temperature angular power spectra retrieved from `CAMB` via Cobaya given the parameters values fixed in exercise 1.\n",
    "\n",
    "* **Exercise 3**: Plot the CMB Temperature angular power spectra retrieved from `CAMB` via Cobaya given a very different value for $\\Omega_b$. Compare with the result of exercise 2 by making a plot of the difference between the angular power spectra. Calculate the difference in the likelihood. Follow what you have learnt in exercise 1.\n",
    "\n",
    "* **Bonus exercise**: Repeat everything in exercises 1, 2 and 3 given a modified CAMB that contains a feature in the primordial power spectrum. This exercise will unveil the full power of Cobaya and why it is useful for the Euclid Consortium. There is a dedicated notebook called `Cobaya-BonusExercise.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0: \n",
    "\n",
    "Plot the chains corresponding to the $\\Lambda$CDM model that you left running yesterday to see the evolution.\n",
    "\n",
    "Alternatively, plot the the chains in the corresponding tar file of the respository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chains and the updated config file from the previous run\n",
    "# Use the function loadMCSamples from getdist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: \n",
    "\n",
    "Make an evaluation of the posterior distribution by running Cobaya with its model wrapper and the Planck18 TT data set. Repeat for the Planck18 TT data including lensing. Think about the values of the likelihood and the posterior. Why are they varying? What are we sampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are running Cobaya with Planck18 data\n",
    "# Let's start by defining the corresponding config file\n",
    "# The options that can be modified by the user are pointed with the acronym (UC).\n",
    "# Note that currently all the parameters are fixed!\n",
    "\n",
    "# Fill the info dictionary yourself!\n",
    "\n",
    "info = {...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the likelihood of Planck18\n",
    "#'likelihood': Cobaya's protected key of the input dictionary.\n",
    "\n",
    "info['likelihood'] = {...}\n",
    "\n",
    "# Print the full info!\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First: import model wrapper of Cobaya \n",
    "from cobaya.model import get_model\n",
    "\n",
    "#Â The `get_model` wrapper of Cobaya imported in the line above needs a yaml or python dictionary as argument\n",
    "model = get_model(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have an insight about what Cobaya has requested to CAMB to calculate the Planck18 likelihood\n",
    "\n",
    "# (1) Requirements needed by the likelihood code.\n",
    "# That means, which quantities are we asking to the Boltzman (CAMB/CLASS) through Cobaya?\n",
    "print('\\n Requirements \\n')\n",
    "print(model.provider.requirement_providers)\n",
    "# (2) At which values have the requirements been requested (redshift, scales...)?\n",
    "print('\\n Requested \\n')\n",
    "print(model.requested())\n",
    "print('\\n Parameters \\n')\n",
    "print(model.input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a random set of sampled parameters values\n",
    "# Which parameter values are not fixed? If you are sampling you need to\n",
    "# pass a fixed point\n",
    "\n",
    "# You obtain a random point in the parameter space like this\n",
    "point = dict(zip(model.parameterization.sampled_params(),\n",
    "                 model.prior.sample(ignore_external=True)[0]))\n",
    "print('Sampled parameters values: \\n', point)\n",
    "\n",
    "# Make a computation of the logposterior on a set of parameter values\n",
    "logposterior = ...\n",
    "\n",
    "# Print the full logposterior, loglike, logprior and the derived parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "\n",
    "Plot the CMB Temperature angular power spectra retrieved from `CAMB` via Cobaya given the values above. Have a look at https://cobaya.readthedocs.io/en/latest/cosmo_external_likelihood.html to get inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the lines above to see which requirements were selected by the model when Planck18 was specified\n",
    "# In particular, look at model.provider\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot them!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "\n",
    "Plot again the CMB Temperature angular power spectra retrieved from `CAMB` via Cobaya given a very different value for $\\Omega_b$. Keep in mind that you need to fix the nuisance parameters of the Planck18 likelihood. How would you do it?\n",
    "\n",
    "Make a plot plotting the difference between the corresponding temperature angular power spectra. Calculate the difference in the likelihood value for both cases.\n",
    "\n",
    "To do this exercise, I recommend you creating a new model instance of the model wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the info dictionary and modify the entry corresponding to Omega_b\n",
    "info_modified_omegab = info.copy()\n",
    "info_modified_omegab['params']['ombh2'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance with this modified info dictionary\n",
    "\n",
    "# Make an evaluation of the posterior so that you can request the requirements\\\n",
    "# Note that you need to do it in the same point as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the difference in the Cls\n",
    "\n",
    "# Let's plot them!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference in the likelihood values for both models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
